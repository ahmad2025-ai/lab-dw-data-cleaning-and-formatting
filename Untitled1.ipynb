{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fd9a838-77fa-4a02-a580-726b868c7599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.12/site-packages (4.12.3)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.12/site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4 pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5da83375-5e2b-4fa9-9d0f-4f2152dbcd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://inside.fifa.com/fifa-world-ranking/men\"\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Inspect the page to find the correct HTML structure for rankings\n",
    "    # Example: Let's say you want to extract all team names and their ranks\n",
    "    teams = soup.find_all(\"div\", class_=\"rank-team\")  # Find the appropriate HTML class name\n",
    "\n",
    "    for team in teams:\n",
    "        rank = team.find(\"div\", class_=\"rank-position\").text.strip()\n",
    "        name = team.find(\"div\", class_=\"team-name\").text.strip()\n",
    "        print(f\"Rank {rank}: {name}\")\n",
    "else:\n",
    "    print(f\"Failed to fetch the page: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f0fcca3-87a6-4a34-aed0-f376bf4beccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Step 1: Send a GET request to the FIFA rankings page\n",
    "url = \"https://inside.fifa.com/fifa-world-ranking/men\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Step 2: Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    print(\"Page fetched successfully!\")\n",
    "    \n",
    "    # Step 3: Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Step 4: Find the data you need\n",
    "    # Inspect the page structure to find where the rankings are stored\n",
    "    # You can use the developer tools in your browser (right-click → Inspect)\n",
    "    # for example, the ranking might be in a <table> or <div> elements with specific classes\n",
    "    \n",
    "    # Example: We assume rankings are in a <div> with a class of 'ranking' (find the right class for your case)\n",
    "    rankings = soup.find_all(\"div\", class_=\"ranking-item\")  # Replace 'ranking-item' with the actual class name\n",
    "\n",
    "    # Step 5: Print the extracted data (or do further processing)\n",
    "    for rank in rankings[:10]:  # Printing top 10 teams (adjust this as per your needs)\n",
    "        position = rank.find(\"div\", class_=\"position\").text.strip()  # Find the position (rank)\n",
    "        team_name = rank.find(\"div\", class_=\"team-name\").text.strip()  # Find the team name\n",
    "        points = rank.find(\"div\", class_=\"points\").text.strip()  # Find the points (if available)\n",
    "        \n",
    "        print(f\"Rank {position}: {team_name} - {points} points\")\n",
    "\n",
    "else:\n",
    "    print(f\"Failed to fetch page: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "add5e32b-b1f5-4b16-87eb-1d0282d82c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55af816a-1578-48b1-9017-a128e96f2341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully!\n",
      "Empty DataFrame\n",
      "Columns: [Rank, Team, Points]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Fetch the HTML page\n",
    "url = \"https://inside.fifa.com/fifa-world-ranking/men\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Step 2: Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    print(\"Page fetched successfully!\")\n",
    "    \n",
    "    # Step 3: Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "    # Step 4: Find the data you need (adjust the class name as needed based on the page structure)\n",
    "    rankings = soup.find_all(\"div\", class_=\"ranking-item\")  # Replace with the actual class name for rankings\n",
    "\n",
    "    # Step 5: Extract relevant details from the HTML (e.g., rank, team, points)\n",
    "    data = []\n",
    "    for rank in rankings:\n",
    "        position = rank.find(\"div\", class_=\"position\").text.strip()  # Find the position (rank)\n",
    "        team_name = rank.find(\"div\", class_=\"team-name\").text.strip()  # Find the team name\n",
    "        points = rank.find(\"div\", class_=\"points\").text.strip()  # Find the points (if available)\n",
    "        \n",
    "        data.append([position, team_name, points])  # Append data for each team\n",
    "\n",
    "    # Step 6: Convert the data to a pandas DataFrame\n",
    "    df = pd.DataFrame(data, columns=[\"Rank\", \"Team\", \"Points\"])\n",
    "    \n",
    "    # Step 7: Display the DataFrame\n",
    "    print(df.head())  # Show the first few rows of the DataFrame\n",
    "\n",
    "else:\n",
    "    print(f\"Failed to fetch page: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6321ba79-8eb7-499c-9811-e281d5c17fea",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'selenium'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m webdriver\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwebdriver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mby\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m By\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'selenium'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6476a2b-c696-49f5-bfd0-e1b2ab71d4a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'selenium'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m webdriver\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwebdriver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mby\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m By\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'selenium'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Set up the webdriver (make sure to set the path to your chromedriver)\n",
    "driver = webdriver.Chrome(executable_path=\"/path/to/chromedriver\")  # Provide path to chromedriver\n",
    "\n",
    "# Step 1: Open the FIFA rankings page\n",
    "url = \"https://inside.fifa.com/fifa-world-ranking/men\"\n",
    "driver.get(url)\n",
    "\n",
    "# Step 2: Wait for the page to load (adjust the time based on your connection speed)\n",
    "time.sleep(5)  # Wait for 5 seconds (increase if the page loads slowly)\n",
    "\n",
    "# Step 3: Locate the ranking table elements\n",
    "# Update the following line after inspecting the structure of the page\n",
    "ranking_items = driver.find_elements(By.CLASS_NAME, \"ranking__team\")  # Change to the actual class name\n",
    "\n",
    "# Step 4: Extract data (rank, team, points)\n",
    "data = []\n",
    "for item in ranking_items:\n",
    "    try:\n",
    "        rank = item.find_element(By.CLASS_NAME, \"position\").text  # Adjust the class name\n",
    "        team_name = item.find_element(By.CLASS_NAME, \"team-name\").text  # Adjust the class name\n",
    "        points = item.find_element(By.CLASS_NAME, \"points\").text  # Adjust the class name\n",
    "        \n",
    "        data.append([rank, team_name, points])  # Store the data\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Step 5: Convert to DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"Rank\", \"Team\", \"Points\"])\n",
    "\n",
    "# Step 6: Display or save the data\n",
    "print(df.head())\n",
    "\n",
    "# Optionally, save the data to a CSV file\n",
    "df.to_csv(\"fifa_rankings.csv\", index=False)\n",
    "\n",
    "# Step 7: Close the driver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebc56bd8-e97e-4da9-bf96-0fbf41e5d202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://inside.fifa.com/fifa-world-ranking/men\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find the data structure containing the ranking information\n",
    "# (You'll need to inspect the page's HTML structure to identify the relevant tags)\n",
    "\n",
    "# Example of extracting team names (adjust based on page structure)\n",
    "teams = soup.find_all('div', class_='ranking-teams')\n",
    "\n",
    "for team in teams:\n",
    "    print(team.text.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9362c093-3cc0-49dc-8d23-211240793dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Rank, Team]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Send the GET request\n",
    "url = \"https://inside.fifa.com/fifa-world-ranking/men\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Extract relevant data (adjust tags as necessary)\n",
    "teams = [team.text.strip() for team in soup.find_all('div', class_='ranking-teams')]\n",
    "ranks = [rank.text.strip() for rank in soup.find_all('span', class_='rank-number')]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'Rank': ranks, 'Team': teams})\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be406db9-0bd2-488a-92eb-0b386133a5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.29.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Collecting webdriver-manager\n",
      "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /opt/anaconda3/lib/python3.12/site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.3)\n",
      "Collecting trio~=0.17 (from selenium)\n",
      "  Downloading trio-0.29.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium)\n",
      "  Downloading trio_websocket-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /opt/anaconda3/lib/python3.12/site-packages (from selenium) (2024.8.30)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in /opt/anaconda3/lib/python3.12/site-packages (from selenium) (4.11.0)\n",
      "Requirement already satisfied: websocket-client~=1.8 in /opt/anaconda3/lib/python3.12/site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from webdriver-manager) (2.32.3)\n",
      "Requirement already satisfied: python-dotenv in /opt/anaconda3/lib/python3.12/site-packages (from webdriver-manager) (0.21.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from webdriver-manager) (24.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Collecting attrs>=23.2.0 (from trio~=0.17->selenium)\n",
      "  Downloading attrs-25.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: sortedcontainers in /opt/anaconda3/lib/python3.12/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/lib/python3.12/site-packages (from trio~=0.17->selenium) (3.7)\n",
      "Collecting outcome (from trio~=0.17->selenium)\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /opt/anaconda3/lib/python3.12/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->webdriver-manager) (3.3.2)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Downloading selenium-4.29.0-py3-none-any.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
      "Downloading trio-0.29.0-py3-none-any.whl (492 kB)\n",
      "Downloading trio_websocket-0.12.1-py3-none-any.whl (21 kB)\n",
      "Downloading attrs-25.1.0-py3-none-any.whl (63 kB)\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: wsproto, attrs, webdriver-manager, outcome, trio, trio-websocket, selenium\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 23.1.0\n",
      "    Uninstalling attrs-23.1.0:\n",
      "      Successfully uninstalled attrs-23.1.0\n",
      "Successfully installed attrs-25.1.0 outcome-1.3.0.post0 selenium-4.29.0 trio-0.29.0 trio-websocket-0.12.1 webdriver-manager-4.0.2 wsproto-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium pandas webdriver-manager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2745748e-1ccd-4aa4-8beb-e16a2a851fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Rank, Team]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Setup the Selenium driver\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "# Access the URL\n",
    "url = \"https://inside.fifa.com/fifa-world-ranking/men\"\n",
    "driver.get(url)\n",
    "\n",
    "# Give time for the page to load\n",
    "time.sleep(5)\n",
    "\n",
    "# Extract the relevant data\n",
    "ranks = [rank.text.strip() for rank in driver.find_elements(By.CLASS_NAME, 'rank-number')]\n",
    "teams = [team.text.strip() for team in driver.find_elements(By.CLASS_NAME, 'ranking-teams')]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'Rank': ranks, 'Team': teams})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5202e58-b717-4bdd-b25f-a8e05edd1964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /opt/anaconda3/lib/python3.12/site-packages (4.29.0)\n",
      "Requirement already satisfied: webdriver-manager in /opt/anaconda3/lib/python3.12/site-packages (4.0.2)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /opt/anaconda3/lib/python3.12/site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.3)\n",
      "Requirement already satisfied: trio~=0.17 in /opt/anaconda3/lib/python3.12/site-packages (from selenium) (0.29.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /opt/anaconda3/lib/python3.12/site-packages (from selenium) (0.12.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /opt/anaconda3/lib/python3.12/site-packages (from selenium) (2024.8.30)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in /opt/anaconda3/lib/python3.12/site-packages (from selenium) (4.11.0)\n",
      "Requirement already satisfied: websocket-client~=1.8 in /opt/anaconda3/lib/python3.12/site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from webdriver-manager) (2.32.3)\n",
      "Requirement already satisfied: python-dotenv in /opt/anaconda3/lib/python3.12/site-packages (from webdriver-manager) (0.21.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from webdriver-manager) (24.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from trio~=0.17->selenium) (25.1.0)\n",
      "Requirement already satisfied: sortedcontainers in /opt/anaconda3/lib/python3.12/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/lib/python3.12/site-packages (from trio~=0.17->selenium) (3.7)\n",
      "Requirement already satisfied: outcome in /opt/anaconda3/lib/python3.12/site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in /opt/anaconda3/lib/python3.12/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /opt/anaconda3/lib/python3.12/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->webdriver-manager) (3.3.2)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium webdriver-manager pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34d443fc-36cb-4653-938e-8159a292855a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Rank, Team]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Setup driver\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "# Open URL\n",
    "url = \"https://inside.fifa.com/fifa-world-ranking/men\"\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for the page to load (increase time if necessary)\n",
    "time.sleep(10)\n",
    "\n",
    "# Extract the teams and ranks\n",
    "teams = driver.find_elements(By.XPATH, \"//div[contains(@class, 'ranking-teams')]//a\")\n",
    "ranks = driver.find_elements(By.XPATH, \"//div[contains(@class, 'rank-number')]\")\n",
    "\n",
    "# Create DataFrame\n",
    "team_names = [team.text.strip() for team in teams]\n",
    "rank_numbers = [rank.text.strip() for rank in ranks]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'Rank': rank_numbers, 'Team': team_names})\n",
    "\n",
    "# Show the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b36c78-ab6b-43e5-a25b-ac961d629d69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
