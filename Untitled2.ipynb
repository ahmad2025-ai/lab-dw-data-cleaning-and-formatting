{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a8f97b1-b6ff-4344-a823-92d4c499e727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.12/site-packages (4.12.3)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.12/site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4 requests pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03466742-5142-4b20-9f9c-a881628d8062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to retrieve the page. Status code: 403\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the Transfermarkt rankings page\n",
    "url = \"https://www.transfermarkt.com/statistik/weltrangliste\"\n",
    "\n",
    "# Send a request to the webpage\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    print(\"Page loaded successfully!\")\n",
    "    \n",
    "    # Parse the HTML content of the page\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Find the table containing the rankings (this can be adjusted if the page structure changes)\n",
    "    table = soup.find('table', {'class': 'items'})  # Look for the table with class \"items\"\n",
    "    \n",
    "    # Extract the headers (columns) of the table\n",
    "    headers = [header.text.strip() for header in table.find_all('th')]\n",
    "    \n",
    "    # Extract the rows (data) of the table\n",
    "    rows = table.find_all('tr')[1:]  # Skip the header row\n",
    "    \n",
    "    # Initialize an empty list to hold the row data\n",
    "    data = []\n",
    "    \n",
    "    # Loop through each row and extract the columns\n",
    "    for row in rows:\n",
    "        columns = row.find_all('td')\n",
    "        \n",
    "        # Extract the relevant data from each column and clean it\n",
    "        rank = columns[0].text.strip()\n",
    "        team = columns[1].find('img')['alt'] if columns[1].find('img') else columns[1].text.strip()\n",
    "        points = columns[2].text.strip()\n",
    "        \n",
    "        # Add the data to the list\n",
    "        data.append([rank, team, points])\n",
    "    \n",
    "    # Create a pandas DataFrame from the extracted data\n",
    "    df = pd.DataFrame(data, columns=headers[:3])  # Use only the first 3 headers (Rank, Team, Points)\n",
    "    \n",
    "    # Display the DataFrame\n",
    "    print(df)\n",
    "else:\n",
    "    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d25e0d0a-decd-4a1a-b401-8ea473da851f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page loaded successfully!\n",
      "     #         Nation Squad size\n",
      "0    1      Argentina         25\n",
      "1    2         France         23\n",
      "2    3          Spain         24\n",
      "3    4        England         23\n",
      "4    5         Brazil         23\n",
      "5    6       Portugal         26\n",
      "6    7    Netherlands         25\n",
      "7    8        Belgium         19\n",
      "8    9          Italy         23\n",
      "9   10        Germany         22\n",
      "10  11        Uruguay         22\n",
      "11  12       Colombia         26\n",
      "12  13        Croatia         26\n",
      "13  14        Morocco         26\n",
      "14  15          Japan         27\n",
      "15  16  United States         23\n",
      "16  17        Senegal         23\n",
      "17  18           Iran         28\n",
      "18  19         Mexico         27\n",
      "19  20    Switzerland         22\n",
      "20  21        Denmark         26\n",
      "21  22        Austria         24\n",
      "22  23    South Korea         26\n",
      "23  24        Ecuador         25\n",
      "24  25        Ukraine         22\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the Transfermarkt rankings page\n",
    "url = \"https://www.transfermarkt.com/statistik/weltrangliste\"\n",
    "\n",
    "# Set up headers to mimic a real browser request\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Send a request to the webpage with the custom header\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    print(\"Page loaded successfully!\")\n",
    "    \n",
    "    # Parse the HTML content of the page\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Find the table containing the rankings (this can be adjusted if the page structure changes)\n",
    "    table = soup.find('table', {'class': 'items'})  # Look for the table with class \"items\"\n",
    "    \n",
    "    # Extract the headers (columns) of the table\n",
    "    headers = [header.text.strip() for header in table.find_all('th')]\n",
    "    \n",
    "    # Extract the rows (data) of the table\n",
    "    rows = table.find_all('tr')[1:]  # Skip the header row\n",
    "    \n",
    "    # Initialize an empty list to hold the row data\n",
    "    data = []\n",
    "    \n",
    "    # Loop through each row and extract the columns\n",
    "    for row in rows:\n",
    "        columns = row.find_all('td')\n",
    "        \n",
    "        # Extract the relevant data from each column and clean it\n",
    "        rank = columns[0].text.strip()\n",
    "        team = columns[1].find('img')['alt'] if columns[1].find('img') else columns[1].text.strip()\n",
    "        points = columns[2].text.strip()\n",
    "        \n",
    "        # Add the data to the list\n",
    "        data.append([rank, team, points])\n",
    "    \n",
    "    # Create a pandas DataFrame from the extracted data\n",
    "    df = pd.DataFrame(data, columns=headers[:3])  # Use only the first 3 headers (Rank, Team, Points)\n",
    "    \n",
    "    # Display the DataFrame\n",
    "    print(df)\n",
    "else:\n",
    "    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "561f1a61-0af2-4b24-b5e4-103ea01ec7bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page loaded successfully!\n",
      "     #         Nation Squad size\n",
      "0    1      Argentina         25\n",
      "1    2         France         23\n",
      "2    3          Spain         24\n",
      "3    4        England         23\n",
      "4    5         Brazil         23\n",
      "5    6       Portugal         26\n",
      "6    7    Netherlands         25\n",
      "7    8        Belgium         19\n",
      "8    9          Italy         23\n",
      "9   10        Germany         22\n",
      "10  11        Uruguay         22\n",
      "11  12       Colombia         26\n",
      "12  13        Croatia         26\n",
      "13  14        Morocco         26\n",
      "14  15          Japan         27\n",
      "15  16  United States         23\n",
      "16  17        Senegal         23\n",
      "17  18           Iran         28\n",
      "18  19         Mexico         27\n",
      "19  20    Switzerland         22\n",
      "20  21        Denmark         26\n",
      "21  22        Austria         24\n",
      "22  23    South Korea         26\n",
      "23  24        Ecuador         25\n",
      "24  25        Ukraine         22\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the Transfermarkt rankings page\n",
    "url = \"https://www.transfermarkt.com/statistik/weltrangliste\"\n",
    "\n",
    "# Set up headers to mimic a real browser request\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Send a request to the webpage with the custom header\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    print(\"Page loaded successfully!\")\n",
    "    \n",
    "    # Parse the HTML content of the page\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Find the table containing the rankings (this can be adjusted if the page structure changes)\n",
    "    table = soup.find('table', {'class': 'items'})  # Look for the table with class \"items\"\n",
    "    \n",
    "    # Extract the headers (columns) of the table\n",
    "    headers = [header.text.strip() for header in table.find_all('th')]\n",
    "    \n",
    "    # Extract the rows (data) of the table\n",
    "    rows = table.find_all('tr')[1:]  # Skip the header row\n",
    "    \n",
    "    # Initialize an empty list to hold the row data\n",
    "    data = []\n",
    "    \n",
    "    # Loop through each row and extract the columns\n",
    "    for row in rows:\n",
    "        columns = row.find_all('td')\n",
    "        \n",
    "        # Extract the relevant data from each column and clean it\n",
    "        rank = columns[0].text.strip()\n",
    "        team = columns[1].find('img')['alt'] if columns[1].find('img') else columns[1].text.strip()\n",
    "        points = columns[2].text.strip()\n",
    "        \n",
    "        # Add the data to the list\n",
    "        data.append([rank, team, points])\n",
    "    \n",
    "    # Create a pandas DataFrame from the extracted data\n",
    "    df = pd.DataFrame(data, columns=headers[:3])  # Use only the first 3 headers (Rank, Team, Points)\n",
    "    \n",
    "    # Display the DataFrame\n",
    "    print(df)\n",
    "else:\n",
    "    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99f28986-6dbd-47dc-8e9e-09f9b959e49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page loaded successfully!\n",
      "     #         Nation Squad size Avg. age Total value Confederation Points\n",
      "0    1      Argentina         25     27.5    €716.50m      CONMEBOL   1867\n",
      "1    2         France         23     26.8    €978.00m          UEFA   1860\n",
      "2    3          Spain         24     25.9    €890.00m          UEFA   1853\n",
      "3    4        England         23     25.3    €995.00m          UEFA   1814\n",
      "4    5         Brazil         23     27.0    €921.80m      CONMEBOL   1776\n",
      "5    6       Portugal         26     26.1    €835.00m          UEFA   1756\n",
      "6    7    Netherlands         25     26.2    €776.50m          UEFA   1748\n",
      "7    8        Belgium         19     24.9    €333.00m          UEFA   1741\n",
      "8    9          Italy         23     25.3    €729.00m          UEFA   1732\n",
      "9   10        Germany         22     28.6    €781.00m          UEFA   1704\n",
      "10  11        Uruguay         22     26.5    €398.00m      CONMEBOL   1696\n",
      "11  12       Colombia         26     29.0    €291.20m      CONMEBOL   1694\n",
      "12  13        Croatia         26     27.9    €289.20m          UEFA   1692\n",
      "13  14        Morocco         26     26.7    €386.50m           CAF   1688\n",
      "14  15          Japan         27     27.1    €280.50m           AFC   1653\n",
      "15  16  United States         23     25.5     €61.10m      CONCACAF   1645\n",
      "16  17        Senegal         23     27.7    €249.00m           CAF   1637\n",
      "17  18           Iran         28     28.1     €46.65m           AFC   1635\n",
      "18  19         Mexico         27     27.7    €163.95m      CONCACAF   1627\n",
      "19  20    Switzerland         22     27.6    €173.90m          UEFA   1625\n",
      "20  21        Denmark         26     26.6    €415.25m          UEFA   1611\n",
      "21  22        Austria         24     28.0    €212.10m          UEFA   1590\n",
      "22  23    South Korea         26     28.3    €158.15m           AFC   1585\n",
      "23  24        Ecuador         25     26.0    €275.50m      CONMEBOL   1560\n",
      "24  25        Ukraine         22     25.8    €286.00m          UEFA   1555\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the Transfermarkt rankings page\n",
    "url = \"https://www.transfermarkt.com/statistik/weltrangliste\"\n",
    "\n",
    "# Set up headers to mimic a real browser request\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Send a request to the webpage with the custom header\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    print(\"Page loaded successfully!\")\n",
    "    \n",
    "    # Parse the HTML content of the page\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Find the table containing the rankings (this can be adjusted if the page structure changes)\n",
    "    table = soup.find('table', {'class': 'items'})  # Look for the table with class \"items\"\n",
    "    \n",
    "    # Extract the headers (columns) of the table\n",
    "    headers = [header.text.strip() for header in table.find_all('th')]\n",
    "    \n",
    "    # Extract the rows (data) of the table\n",
    "    rows = table.find_all('tr')[1:]  # Skip the header row\n",
    "    \n",
    "    # Initialize an empty list to hold the row data\n",
    "    data = []\n",
    "    \n",
    "    # Loop through each row and extract the columns\n",
    "    for row in rows:\n",
    "        columns = row.find_all('td')\n",
    "        \n",
    "        # Extract the relevant data from each column and clean it\n",
    "        rank = columns[0].text.strip()\n",
    "        team = columns[1].find('img')['alt'] if columns[1].find('img') else columns[1].text.strip()\n",
    "        points = columns[2].text.strip()\n",
    "        previous_points = columns[3].text.strip()\n",
    "        rank_change = columns[4].text.strip()\n",
    "        confederation = columns[5].text.strip()\n",
    "        rank_date = columns[6].text.strip()\n",
    "        \n",
    "        # Add the data to the list\n",
    "        data.append([rank, team, points, previous_points, rank_change, confederation, rank_date])\n",
    "    \n",
    "    # Create a pandas DataFrame from the extracted data with all columns\n",
    "    df = pd.DataFrame(data, columns=headers[:7])  # Use the first 7 headers (Rank, Team, Points, etc.)\n",
    "    \n",
    "    # Display the DataFrame\n",
    "    print(df)\n",
    "else:\n",
    "    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bbe144a5-47ff-49b2-a8b0-bc7897e241b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n",
      "Page 1 loaded successfully!\n",
      "Scraping page 2...\n",
      "Page 2 loaded successfully!\n",
      "Scraping page 3...\n",
      "Page 3 loaded successfully!\n",
      "Scraping page 4...\n",
      "Page 4 loaded successfully!\n",
      "Scraping page 5...\n",
      "Page 5 loaded successfully!\n",
      "Scraping page 6...\n",
      "Page 6 loaded successfully!\n",
      "Scraping page 7...\n",
      "Page 7 loaded successfully!\n",
      "Scraping page 8...\n",
      "Page 8 loaded successfully!\n",
      "Scraping page 9...\n",
      "Page 9 loaded successfully!\n",
      "    Rank                          Team Points Previous Points Rank Change  \\\n",
      "0      1                     Argentina     25            27.5    €716.50m   \n",
      "1      2                        France     23            26.8    €978.00m   \n",
      "2      3                         Spain     24            25.9    €890.00m   \n",
      "3      4                       England     23            25.3    €995.00m   \n",
      "4      5                        Brazil     23            27.0    €921.80m   \n",
      "..   ...                           ...    ...             ...         ...   \n",
      "205  206      Turks and Caicos Islands     16            20.8        €75k   \n",
      "206  207        British Virgin Islands     20            22.0           -   \n",
      "207  208  United States Virgin Islands     20            24.7           -   \n",
      "208  209                      Anguilla     22            24.2           -   \n",
      "209  210                    San Marino     24            24.9      €1.08m   \n",
      "\n",
      "    Confederation Rank Date  \n",
      "0        CONMEBOL      1867  \n",
      "1            UEFA      1860  \n",
      "2            UEFA      1853  \n",
      "3            UEFA      1814  \n",
      "4        CONMEBOL      1776  \n",
      "..            ...       ...  \n",
      "205      CONCACAF       804  \n",
      "206      CONCACAF       780  \n",
      "207      CONCACAF       780  \n",
      "208      CONCACAF       769  \n",
      "209          UEFA       747  \n",
      "\n",
      "[210 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Base URL of the Transfermarkt rankings page\n",
    "url_base = \"https://www.transfermarkt.com/statistik/weltrangliste?page=\"\n",
    "\n",
    "# Set up headers to mimic a real browser request\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# List to hold data from all pages\n",
    "all_data = []\n",
    "\n",
    "# Loop through pages 1 to 9 (since there are 9 pages in total)\n",
    "for page in range(1, 10):  # Scraping 9 pages\n",
    "    print(f\"Scraping page {page}...\")\n",
    "    \n",
    "    # Send a request to the webpage with the custom header\n",
    "    response = requests.get(url_base + str(page), headers=headers)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        print(f\"Page {page} loaded successfully!\")\n",
    "        \n",
    "        # Parse the HTML content of the page\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Find the table containing the rankings (this can be adjusted if the page structure changes)\n",
    "        table = soup.find('table', {'class': 'items'})  # Look for the table with class \"items\"\n",
    "        \n",
    "        # Extract the rows (data) of the table\n",
    "        rows = table.find_all('tr')[1:]  # Skip the header row\n",
    "        \n",
    "        # Loop through each row and extract the columns\n",
    "        for row in rows:\n",
    "            columns = row.find_all('td')\n",
    "            \n",
    "            # Extract the relevant data from each column and clean it\n",
    "            rank = columns[0].text.strip()\n",
    "            team = columns[1].find('img')['alt'] if columns[1].find('img') else columns[1].text.strip()\n",
    "            points = columns[2].text.strip()\n",
    "            previous_points = columns[3].text.strip()\n",
    "            rank_change = columns[4].text.strip()\n",
    "            confederation = columns[5].text.strip()\n",
    "            rank_date = columns[6].text.strip()\n",
    "            \n",
    "            # Add the data to the list\n",
    "            all_data.append([rank, team, points, previous_points, rank_change, confederation, rank_date])\n",
    "    else:\n",
    "        print(f\"Failed to retrieve page {page}. Status code: {response.status_code}\")\n",
    "\n",
    "# Create a pandas DataFrame from the extracted data with all columns\n",
    "headers = ['Rank', 'Team', 'Points', 'Previous Points', 'Rank Change', 'Confederation', 'Rank Date']\n",
    "df = pd.DataFrame(all_data, columns=headers)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Optionally, save the DataFrame to a CSV file\n",
    " #df.to_csv('transfermarkt_ranking_all_pages.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca6303f1-ae44-4519-8f55-439e4897dff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n",
      "Page 1 loaded successfully!\n",
      "Scraping page 2...\n",
      "Page 2 loaded successfully!\n",
      "Scraping page 3...\n",
      "Page 3 loaded successfully!\n",
      "Scraping page 4...\n",
      "Page 4 loaded successfully!\n",
      "Scraping page 5...\n",
      "Page 5 loaded successfully!\n",
      "Scraping page 6...\n",
      "Page 6 loaded successfully!\n",
      "Scraping page 7...\n",
      "Page 7 loaded successfully!\n",
      "Scraping page 8...\n",
      "Page 8 loaded successfully!\n",
      "Scraping page 9...\n",
      "Page 9 loaded successfully!\n",
      "     Rank                          Team Points Previous Points Rank Change  \\\n",
      "0       1                     Argentina     25            27.5    €716.50m   \n",
      "1       2                        France     23            26.8    €978.00m   \n",
      "2       3                         Spain     24            25.9    €890.00m   \n",
      "3       4                       England     23            25.3    €995.00m   \n",
      "4       5                        Brazil     23            27.0    €921.80m   \n",
      "..    ...                           ...    ...             ...         ...   \n",
      "205   206      Turks and Caicos Islands     16            20.8        €75k   \n",
      "206   207        British Virgin Islands     20            22.0           -   \n",
      "207   208  United States Virgin Islands     20            24.7           -   \n",
      "208   209                      Anguilla     22            24.2           -   \n",
      "209   210                    San Marino     24            24.9      €1.08m   \n",
      "\n",
      "    Confederation Rank Date  \n",
      "0        CONMEBOL      1867  \n",
      "1            UEFA      1860  \n",
      "2            UEFA      1853  \n",
      "3            UEFA      1814  \n",
      "4        CONMEBOL      1776  \n",
      "..            ...       ...  \n",
      "205      CONCACAF       804  \n",
      "206      CONCACAF       780  \n",
      "207      CONCACAF       780  \n",
      "208      CONCACAF       769  \n",
      "209          UEFA       747  \n",
      "\n",
      "[210 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Base URL of the Transfermarkt rankings page\n",
    "url_base = \"https://www.transfermarkt.com/statistik/weltrangliste?page=\"\n",
    "\n",
    "# Set up headers to mimic a real browser request\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# List to hold data from all pages\n",
    "all_data = []\n",
    "\n",
    "# Loop through pages 1 to 9 (since there are 9 pages in total)\n",
    "for page in range(1, 10):  # Scraping 9 pages\n",
    "    print(f\"Scraping page {page}...\")\n",
    "    \n",
    "    # Send a request to the webpage with the custom header\n",
    "    response = requests.get(url_base + str(page), headers=headers)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        print(f\"Page {page} loaded successfully!\")\n",
    "        \n",
    "        # Parse the HTML content of the page\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Find the table containing the rankings (this can be adjusted if the page structure changes)\n",
    "        table = soup.find('table', {'class': 'items'})  # Look for the table with class \"items\"\n",
    "        \n",
    "        # Extract the rows (data) of the table\n",
    "        rows = table.find_all('tr')[1:]  # Skip the header row\n",
    "        \n",
    "        # Loop through each row and extract the columns\n",
    "        for row in rows:\n",
    "            columns = row.find_all('td')\n",
    "            \n",
    "            # Extract the relevant data from each column and clean it\n",
    "            rank = columns[0].text.strip()\n",
    "            team = columns[1].find('img')['alt'] if columns[1].find('img') else columns[1].text.strip()\n",
    "            points = columns[2].text.strip()\n",
    "            previous_points = columns[3].text.strip()\n",
    "            rank_change = columns[4].text.strip()\n",
    "            confederation = columns[5].text.strip()\n",
    "            rank_date = columns[6].text.strip()\n",
    "            \n",
    "            # Add the data to the list\n",
    "            all_data.append([rank, team, points, previous_points, rank_change, confederation, rank_date])\n",
    "    else:\n",
    "        print(f\"Failed to retrieve page {page}. Status code: {response.status_code}\")\n",
    "\n",
    "# Create a pandas DataFrame from the extracted data with all columns\n",
    "headers = ['Rank', 'Team', 'Points', 'Previous Points', 'Rank Change', 'Confederation', 'Rank Date']\n",
    "df = pd.DataFrame(all_data, columns=headers)\n",
    "\n",
    "# Convert the \"Rank\" column to numeric for proper sorting\n",
    "df['Rank'] = pd.to_numeric(df['Rank'], errors='coerce')\n",
    "\n",
    "# Sort the DataFrame by \"Rank\" in ascending order (smallest rank value is the best)\n",
    "df_sorted = df.sort_values(by='Rank', ascending=True)\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "print(df_sorted)\n",
    "\n",
    "# Optionally, save the sorted DataFrame to a CSV file\n",
    "# df_sorted.to_csv('sorted_transfermarkt_ranking.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8183c669-7090-4b69-a1b8-5e5763b10430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the sorted DataFrame to a CSV file\n",
    "df_sorted.to_csv('sorted_transfermarkt_ranking.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fec8bd43-3d00-42d8-a2d0-3cee45bd7833",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:59: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:59: SyntaxWarning: invalid escape sequence '\\d'\n",
      "/var/folders/l4/g8j3y_vx0pq5tl_95dwxp9hr0000gp/T/ipykernel_14026/1504307934.py:59: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  df['Rank'] = df['Rank'].str.extract('(\\d+)').astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n",
      "Page 1 loaded successfully!\n",
      "Scraping page 2...\n",
      "Page 2 loaded successfully!\n",
      "Scraping page 3...\n",
      "Page 3 loaded successfully!\n",
      "Scraping page 4...\n",
      "Page 4 loaded successfully!\n",
      "Scraping page 5...\n",
      "Page 5 loaded successfully!\n",
      "Scraping page 6...\n",
      "Page 6 loaded successfully!\n",
      "Scraping page 7...\n",
      "Page 7 loaded successfully!\n",
      "Scraping page 8...\n",
      "Page 8 loaded successfully!\n",
      "Scraping page 9...\n",
      "Page 9 loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l4/g8j3y_vx0pq5tl_95dwxp9hr0000gp/T/ipykernel_14026/1504307934.py:59: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  df['Rank'] = df['Rank'].str.extract('(\\d+)').astype(int)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '25k'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 76\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(value) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1e6\u001b[39m  \u001b[38;5;66;03m# Convert to millions (multiply by 1,000,000)\u001b[39;00m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(value)\n\u001b[0;32m---> 76\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal Value\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal Value\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(clean_total_value)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Display the cleaned DataFrame\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCleaned DataFrame:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[1;32m   4918\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4919\u001b[0m         func,\n\u001b[1;32m   4920\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[1;32m   4921\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[1;32m   4922\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   4923\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m-> 4924\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[1;32m   1508\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[1;32m   1509\u001b[0m )\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[47], line 74\u001b[0m, in \u001b[0;36mclean_total_value\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m     72\u001b[0m     value \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(value) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1e6\u001b[39m  \u001b[38;5;66;03m# Convert to millions (multiply by 1,000,000)\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(value)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '25k'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Base URL of the Transfermarkt rankings page\n",
    "url_base = \"https://www.transfermarkt.com/statistik/weltrangliste?page=\"\n",
    "\n",
    "# Set up headers to mimic a real browser request\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# List to hold data from all pages\n",
    "all_data = []\n",
    "\n",
    "# Loop through pages 1 to 9 (since there are 9 pages in total)\n",
    "for page in range(1, 10):  # Scraping 9 pages\n",
    "    print(f\"Scraping page {page}...\")\n",
    "    \n",
    "    # Send a request to the webpage with the custom header\n",
    "    response = requests.get(url_base + str(page), headers=headers)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        print(f\"Page {page} loaded successfully!\")\n",
    "        \n",
    "        # Parse the HTML content of the page\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Find the table containing the rankings (this can be adjusted if the page structure changes)\n",
    "        table = soup.find('table', {'class': 'items'})  # Look for the table with class \"items\"\n",
    "        \n",
    "        # Extract the rows (data) of the table\n",
    "        rows = table.find_all('tr')[1:]  # Skip the header row\n",
    "        \n",
    "        # Loop through each row and extract the columns\n",
    "        for row in rows:\n",
    "            columns = row.find_all('td')\n",
    "            \n",
    "            # Extract the relevant data from each column and clean it\n",
    "            rank = columns[0].text.strip()\n",
    "            nation = columns[1].find('img')['alt'] if columns[1].find('img') else columns[1].text.strip()\n",
    "            squad_size = columns[2].text.strip()\n",
    "            avg_age = columns[3].text.strip()\n",
    "            total_value = columns[4].text.strip()\n",
    "            confederation = columns[5].text.strip()\n",
    "            points = columns[6].text.strip()\n",
    "            \n",
    "            # Add the data to the list\n",
    "            all_data.append([rank, nation, squad_size, avg_age, total_value, confederation, points])\n",
    "    else:\n",
    "        print(f\"Failed to retrieve page {page}. Status code: {response.status_code}\")\n",
    "\n",
    "# Create a pandas DataFrame from the extracted data with the correct headers\n",
    "headers = ['Rank', 'Nation', 'Squad Size', 'Avg Age', 'Total Value', 'Confederation', 'Points']\n",
    "df = pd.DataFrame(all_data, columns=headers)\n",
    "\n",
    "# Clean the \"Rank\" column: remove non-numeric characters (if any)\n",
    "df['Rank'] = df['Rank'].str.extract('(\\d+)').astype(int)\n",
    "\n",
    "# Convert \"Points\" to numeric\n",
    "df['Points'] = pd.to_numeric(df['Points'], errors='coerce')\n",
    "\n",
    "# Convert \"Avg Age\" to numeric\n",
    "df['Avg Age'] = pd.to_numeric(df['Avg Age'], errors='coerce')\n",
    "\n",
    "# Clean \"Total Value\" column by removing non-numeric characters (€, commas, and 'm')\n",
    "def clean_total_value(value):\n",
    "    # Remove commas and '€' symbol, then check if it contains 'm' for million\n",
    "    value = value.replace('€', '').replace(',', '')\n",
    "    if 'm' in value.lower():\n",
    "        value = value.replace('m', '').strip()\n",
    "        return float(value) * 1e6  # Convert to millions (multiply by 1,000,000)\n",
    "    return float(value)\n",
    "\n",
    "df['Total Value'] = df['Total Value'].apply(clean_total_value)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(\"Cleaned DataFrame:\")\n",
    "print(df.head())\n",
    "\n",
    "# Save the cleaned DataFrame to a CSV file\n",
    "#df.to_csv('transfermarkt_rankings.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6b9bbf93-692c-4278-bf1b-2e6fd3b62ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:60: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:60: SyntaxWarning: invalid escape sequence '\\d'\n",
      "/var/folders/l4/g8j3y_vx0pq5tl_95dwxp9hr0000gp/T/ipykernel_14026/2889923072.py:60: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  df['Rank'] = df['Rank'].str.extract('(\\d+)').astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n",
      "Page 1 loaded successfully!\n",
      "Scraping page 2...\n",
      "Page 2 loaded successfully!\n",
      "Scraping page 3...\n",
      "Page 3 loaded successfully!\n",
      "Scraping page 4...\n",
      "Page 4 loaded successfully!\n",
      "Scraping page 5...\n",
      "Page 5 loaded successfully!\n",
      "Scraping page 6...\n",
      "Page 6 loaded successfully!\n",
      "Scraping page 7...\n",
      "Page 7 loaded successfully!\n",
      "Scraping page 8...\n",
      "Page 8 loaded successfully!\n",
      "Scraping page 9...\n",
      "Page 9 loaded successfully!\n",
      "Data types:\n",
      "Rank               int64\n",
      "Nation            object\n",
      "Squad Size          int8\n",
      "Avg Age          float64\n",
      "Total Value      float64\n",
      "Confederation     object\n",
      "Points             int16\n",
      "dtype: object\n",
      "Cleaned DataFrame:\n",
      "   Rank     Nation  Squad Size  Avg Age  Total Value Confederation  Points\n",
      "0     1  Argentina          25     27.5  716500000.0      CONMEBOL    1867\n",
      "1     2     France          23     26.8  978000000.0          UEFA    1860\n",
      "2     3      Spain          24     25.9  890000000.0          UEFA    1853\n",
      "3     4    England          23     25.3  995000000.0          UEFA    1814\n",
      "4     5     Brazil          23     27.0  921800000.0      CONMEBOL    1776\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Base URL of the Transfermarkt rankings page\n",
    "url_base = \"https://www.transfermarkt.com/statistik/weltrangliste?page=\"\n",
    "\n",
    "# Set up headers to mimic a real browser request\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# List to hold data from all pages\n",
    "all_data = []\n",
    "\n",
    "# Loop through pages 1 to 9 (since there are 9 pages in total)\n",
    "for page in range(1, 10):  # Scraping 9 pages\n",
    "    print(f\"Scraping page {page}...\")\n",
    "    \n",
    "    # Send a request to the webpage with the custom header\n",
    "    response = requests.get(url_base + str(page), headers=headers)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        print(f\"Page {page} loaded successfully!\")\n",
    "        \n",
    "        # Parse the HTML content of the page\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Find the table containing the rankings (this can be adjusted if the page structure changes)\n",
    "        table = soup.find('table', {'class': 'items'})  # Look for the table with class \"items\"\n",
    "        \n",
    "        # Extract the rows (data) of the table\n",
    "        rows = table.find_all('tr')[1:]  # Skip the header row\n",
    "        \n",
    "        # Loop through each row and extract the columns\n",
    "        for row in rows:\n",
    "            columns = row.find_all('td')\n",
    "            \n",
    "            # Extract the relevant data from each column and clean it\n",
    "            rank = columns[0].text.strip()\n",
    "            nation = columns[1].find('img')['alt'] if columns[1].find('img') else columns[1].text.strip()\n",
    "            squad_size = columns[2].text.strip()\n",
    "            avg_age = columns[3].text.strip()\n",
    "            total_value = columns[4].text.strip()\n",
    "            confederation = columns[5].text.strip()\n",
    "            points = columns[6].text.strip()\n",
    "            \n",
    "            # Add the data to the list\n",
    "            all_data.append([rank, nation, squad_size, avg_age, total_value, confederation, points])\n",
    "    else:\n",
    "        print(f\"Failed to retrieve page {page}. Status code: {response.status_code}\")\n",
    "\n",
    "# Create a pandas DataFrame from the extracted data with the correct headers\n",
    "headers = ['Rank', 'Nation', 'Squad Size', 'Avg Age', 'Total Value', 'Confederation', 'Points']\n",
    "df = pd.DataFrame(all_data, columns=headers)\n",
    "\n",
    "# Clean the \"Rank\" column: remove non-numeric characters (if any)\n",
    "df['Rank'] = df['Rank'].str.extract('(\\d+)').astype(int)\n",
    "\n",
    "# Convert \"Points\" to numeric (integer)\n",
    "df['Points'] = pd.to_numeric(df['Points'], errors='coerce', downcast='integer')\n",
    "\n",
    "# Convert \"Avg Age\" to float\n",
    "df['Avg Age'] = pd.to_numeric(df['Avg Age'], errors='coerce')\n",
    "\n",
    "# Clean \"Total Value\" column by removing non-numeric characters (€, commas, 'm', 'k', and 'b')\n",
    "def clean_total_value(value):\n",
    "    # If the value is '-', replace with NaN\n",
    "    if value == '-':\n",
    "        return np.nan\n",
    "    \n",
    "    # Remove commas, '€', and strip leading/trailing spaces\n",
    "    value = value.replace('€', '').replace(',', '').strip()\n",
    "    \n",
    "    # Handle 'm' for millions\n",
    "    if 'm' in value.lower():\n",
    "        value = value.replace('m', '').strip()\n",
    "        return float(value) * 1e6  # Convert to millions (multiply by 1,000,000)\n",
    "    \n",
    "    # Handle 'b' for billions\n",
    "    elif 'b' in value.lower():\n",
    "        value = value.replace('b', '').strip()\n",
    "        return float(value) * 1e9  # Convert to billions (multiply by 1,000,000,000)\n",
    "    \n",
    "    # Handle 'k' for thousands\n",
    "    elif 'k' in value.lower():\n",
    "        value = value.replace('k', '').strip()\n",
    "        return float(value) * 1e3  # Convert to thousands (multiply by 1,000)\n",
    "    \n",
    "    # Otherwise, return the value as is (if it's just a plain number)\n",
    "    return float(value)\n",
    "\n",
    "# Apply the function to clean the \"Total Value\" column\n",
    "df['Total Value'] = df['Total Value'].apply(clean_total_value)\n",
    "\n",
    "# Convert \"Squad Size\" to numeric (integer)\n",
    "df['Squad Size'] = pd.to_numeric(df['Squad Size'], errors='coerce', downcast='integer')\n",
    "\n",
    "# Convert \"Confederation\" to object (string), ensuring no unexpected values\n",
    "df['Confederation'] = df['Confederation'].astype(str)\n",
    "\n",
    "# Ensure that the correct data types are set\n",
    "print(f\"Data types:\\n{df.dtypes}\")\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(\"Cleaned DataFrame:\")\n",
    "print(df.head())\n",
    "\n",
    "# Save the cleaned DataFrame to a CSV file\n",
    "df.to_csv('transfermarkt_rankings.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "907800e9-680e-4891-a5c2-5254c427784d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('transfermarkt_rankings.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a57efe42-9d45-40e5-a569-b1130a332909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Nation</th>\n",
       "      <th>Squad Size</th>\n",
       "      <th>Avg Age</th>\n",
       "      <th>Total Value</th>\n",
       "      <th>Confederation</th>\n",
       "      <th>Points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>25</td>\n",
       "      <td>27.5</td>\n",
       "      <td>716500000.0</td>\n",
       "      <td>CONMEBOL</td>\n",
       "      <td>1867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>France</td>\n",
       "      <td>23</td>\n",
       "      <td>26.8</td>\n",
       "      <td>978000000.0</td>\n",
       "      <td>UEFA</td>\n",
       "      <td>1860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Spain</td>\n",
       "      <td>24</td>\n",
       "      <td>25.9</td>\n",
       "      <td>890000000.0</td>\n",
       "      <td>UEFA</td>\n",
       "      <td>1853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>England</td>\n",
       "      <td>23</td>\n",
       "      <td>25.3</td>\n",
       "      <td>995000000.0</td>\n",
       "      <td>UEFA</td>\n",
       "      <td>1814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>23</td>\n",
       "      <td>27.0</td>\n",
       "      <td>921800000.0</td>\n",
       "      <td>CONMEBOL</td>\n",
       "      <td>1776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>206</td>\n",
       "      <td>Turks and Caicos Islands</td>\n",
       "      <td>16</td>\n",
       "      <td>20.8</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>CONCACAF</td>\n",
       "      <td>804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>207</td>\n",
       "      <td>British Virgin Islands</td>\n",
       "      <td>20</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONCACAF</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>208</td>\n",
       "      <td>United States Virgin Islands</td>\n",
       "      <td>20</td>\n",
       "      <td>24.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONCACAF</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>209</td>\n",
       "      <td>Anguilla</td>\n",
       "      <td>22</td>\n",
       "      <td>24.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONCACAF</td>\n",
       "      <td>769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>210</td>\n",
       "      <td>San Marino</td>\n",
       "      <td>24</td>\n",
       "      <td>24.9</td>\n",
       "      <td>1080000.0</td>\n",
       "      <td>UEFA</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rank                        Nation  Squad Size  Avg Age  Total Value  \\\n",
       "0       1                     Argentina          25     27.5  716500000.0   \n",
       "1       2                        France          23     26.8  978000000.0   \n",
       "2       3                         Spain          24     25.9  890000000.0   \n",
       "3       4                       England          23     25.3  995000000.0   \n",
       "4       5                        Brazil          23     27.0  921800000.0   \n",
       "..    ...                           ...         ...      ...          ...   \n",
       "205   206      Turks and Caicos Islands          16     20.8      75000.0   \n",
       "206   207        British Virgin Islands          20     22.0          NaN   \n",
       "207   208  United States Virgin Islands          20     24.7          NaN   \n",
       "208   209                      Anguilla          22     24.2          NaN   \n",
       "209   210                    San Marino          24     24.9    1080000.0   \n",
       "\n",
       "    Confederation  Points  \n",
       "0        CONMEBOL    1867  \n",
       "1            UEFA    1860  \n",
       "2            UEFA    1853  \n",
       "3            UEFA    1814  \n",
       "4        CONMEBOL    1776  \n",
       "..            ...     ...  \n",
       "205      CONCACAF     804  \n",
       "206      CONCACAF     780  \n",
       "207      CONCACAF     780  \n",
       "208      CONCACAF     769  \n",
       "209          UEFA     747  \n",
       "\n",
       "[210 rows x 7 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5f5dacac-00d2-48b4-86ab-76be718eae65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.to_csv('/Users/ahmadkhalilghamai/Desktop/transfermarket/transfermarkt_rankings.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a7626fd4-40a7-42a2-a89b-c96ffc14bbd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Nation</th>\n",
       "      <th>Squad Size</th>\n",
       "      <th>Avg Age</th>\n",
       "      <th>Total Value</th>\n",
       "      <th>Confederation</th>\n",
       "      <th>Points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>25</td>\n",
       "      <td>27.5</td>\n",
       "      <td>716500000.0</td>\n",
       "      <td>CONMEBOL</td>\n",
       "      <td>1867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>France</td>\n",
       "      <td>23</td>\n",
       "      <td>26.8</td>\n",
       "      <td>978000000.0</td>\n",
       "      <td>UEFA</td>\n",
       "      <td>1860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Spain</td>\n",
       "      <td>24</td>\n",
       "      <td>25.9</td>\n",
       "      <td>890000000.0</td>\n",
       "      <td>UEFA</td>\n",
       "      <td>1853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>England</td>\n",
       "      <td>23</td>\n",
       "      <td>25.3</td>\n",
       "      <td>995000000.0</td>\n",
       "      <td>UEFA</td>\n",
       "      <td>1814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>23</td>\n",
       "      <td>27.0</td>\n",
       "      <td>921800000.0</td>\n",
       "      <td>CONMEBOL</td>\n",
       "      <td>1776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank     Nation  Squad Size  Avg Age  Total Value Confederation  Points\n",
       "0     1  Argentina          25     27.5  716500000.0      CONMEBOL    1867\n",
       "1     2     France          23     26.8  978000000.0          UEFA    1860\n",
       "2     3      Spain          24     25.9  890000000.0          UEFA    1853\n",
       "3     4    England          23     25.3  995000000.0          UEFA    1814\n",
       "4     5     Brazil          23     27.0  921800000.0      CONMEBOL    1776"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the path to the CSV file you saved earlier\n",
    "file_path = '/Users/ahmadkhalilghamai/Desktop/transfermarket/transfermarkt_rankings.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows to confirm\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b05e1230-ac3f-4154-96e4-7f8ed02bb9cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Nation</th>\n",
       "      <th>Squad Size</th>\n",
       "      <th>Avg Age</th>\n",
       "      <th>Total Value</th>\n",
       "      <th>Confederation</th>\n",
       "      <th>Points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Rank  Nation  Squad Size  Avg Age  Total Value  Confederation  Points\n",
       "0    False   False       False    False        False          False   False\n",
       "1    False   False       False    False        False          False   False\n",
       "2    False   False       False    False        False          False   False\n",
       "3    False   False       False    False        False          False   False\n",
       "4    False   False       False    False        False          False   False\n",
       "..     ...     ...         ...      ...          ...            ...     ...\n",
       "205  False   False       False    False        False          False   False\n",
       "206  False   False       False    False         True          False   False\n",
       "207  False   False       False    False         True          False   False\n",
       "208  False   False       False    False         True          False   False\n",
       "209  False   False       False    False        False          False   False\n",
       "\n",
       "[210 rows x 7 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
